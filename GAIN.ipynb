{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creator: Dhanajit Brahma\n",
    "\n",
    "Adapted from the original implementation in tensorflow from here: https://github.com/jsyoon0823/GAIN\n",
    "\n",
    "Generative Adversarial Imputation Networks (GAIN) Implementation on Letter and Spam Dataset\n",
    "Reference: J. Yoon, J. Jordon, M. van der Schaar, \"GAIN: Missing Data Imputation using Generative Adversarial Nets,\" ICML, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Packages\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = 'Letter.csv'  # 'Letter.csv' for Letter dataset an 'Spam.csv' for Spam dataset\n",
    "use_gpu = True  # set it to True to use GPU and False to use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% System Parameters\n",
    "# 1. Mini batch size\n",
    "mb_size = 128\n",
    "# 2. Missing rate\n",
    "p_miss = 0.2\n",
    "# 3. Hint rate\n",
    "p_hint = 0.9\n",
    "# 4. Loss Hyperparameters\n",
    "alpha = 10\n",
    "# 5. Train Rate\n",
    "train_rate = 0.8\n",
    "\n",
    "#%% Data\n",
    "\n",
    "# Data generation\n",
    "Data = np.loadtxt(dataset_file, delimiter=\",\",skiprows=1)\n",
    "\n",
    "# Parameters\n",
    "No = len(Data)\n",
    "Dim = len(Data[0,:])\n",
    "\n",
    "# Hidden state dimensions\n",
    "H_Dim1 = Dim\n",
    "H_Dim2 = Dim\n",
    "\n",
    "# Normalization (0 to 1)\n",
    "Min_Val = np.zeros(Dim)\n",
    "Max_Val = np.zeros(Dim)\n",
    "\n",
    "for i in range(Dim):\n",
    "    Min_Val[i] = np.min(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n",
    "    Max_Val[i] = np.max(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n",
    "\n",
    "#%% Missing introducing\n",
    "p_miss_vec = p_miss * np.ones((Dim,1)) \n",
    "   \n",
    "Missing = np.zeros((No,Dim))\n",
    "\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    Missing[:,i] = 1.*B\n",
    "\n",
    "    \n",
    "#%% Train Test Division    \n",
    "   \n",
    "idx = np.random.permutation(No)\n",
    "\n",
    "Train_No = int(No * train_rate)\n",
    "Test_No = No - Train_No\n",
    "    \n",
    "# Train / Test Features\n",
    "trainX = Data[idx[:Train_No],:]\n",
    "testX = Data[idx[Train_No:],:]\n",
    "\n",
    "# Train / Test Missing Indicators\n",
    "trainM = Missing[idx[:Train_No],:]\n",
    "testM = Missing[idx[Train_No:],:]\n",
    "\n",
    "#%% Necessary Functions\n",
    "\n",
    "# 1. Xavier Initialization Definition\n",
    "# def xavier_init(size):\n",
    "#     in_dim = size[0]\n",
    "#     xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "#     return tf.random_normal(shape = size, stddev = xavier_stddev)\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return np.random.normal(size = size, scale = xavier_stddev)\n",
    "    \n",
    "# Hint Vector Generation\n",
    "def sample_M(m, n, p):\n",
    "    A = np.random.uniform(0., 1., size = [m, n])\n",
    "    B = A > p\n",
    "    C = 1.*B\n",
    "    return C\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GAIN Consists of 3 Components\n",
    "- Generator\n",
    "- Discriminator\n",
    "- Hint Mechanism\n",
    "'''   \n",
    "   \n",
    "#%% GAIN Architecture   \n",
    "   \n",
    "# #%% 1. Input Placeholders\n",
    "# # 1.1. Data Vector\n",
    "# X = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "# # 1.2. Mask Vector \n",
    "# M = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "# # 1.3. Hint vector\n",
    "# H = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "# # 1.4. X with missing values\n",
    "# New_X = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "\n",
    "#%% 2. Discriminator\n",
    "if use_gpu is True:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")       # Output is multi-variate\n",
    "else:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)       # Output is multi-variate\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
    "\n",
    "#%% 3. Generator\n",
    "if use_gpu is True:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")\n",
    "else:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% GAIN Function\n",
    "\n",
    "#%% 1. Generator\n",
    "def generator(new_x,m):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,m])  # Mask + Data Concatenate\n",
    "    G_h1 = F.relu(torch.matmul(inputs, G_W1) + G_b1)\n",
    "    G_h2 = F.relu(torch.matmul(G_h1, G_W2) + G_b2)   \n",
    "    G_prob = torch.sigmoid(torch.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n",
    "    \n",
    "    return G_prob\n",
    "\n",
    "#%% 2. Discriminator\n",
    "def discriminator(new_x, h):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,h])  # Hint + Data Concatenate\n",
    "    D_h1 = F.relu(torch.matmul(inputs, D_W1) + D_b1)  \n",
    "    D_h2 = F.relu(torch.matmul(D_h1, D_W2) + D_b2)\n",
    "    D_logit = torch.matmul(D_h2, D_W3) + D_b3\n",
    "    D_prob = torch.sigmoid(D_logit)  # [0,1] Probability Output\n",
    "    \n",
    "    return D_prob\n",
    "\n",
    "#%% 3. Other functions\n",
    "# Random sample generator for Z\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(0., 0.01, size = [m, n])        \n",
    "\n",
    "# Mini-batch generation\n",
    "def sample_idx(m, n):\n",
    "    A = np.random.permutation(m)\n",
    "    idx = A[:n]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(M, New_X, H):\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    D_loss = -torch.mean(M * torch.log(D_prob + 1e-8) + (1-M) * torch.log(1. - D_prob + 1e-8))\n",
    "    return D_loss\n",
    "\n",
    "def generator_loss(X, M, New_X, H):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    G_loss1 = -torch.mean((1-M) * torch.log(D_prob + 1e-8))\n",
    "    MSE_train_loss = torch.mean((M * New_X - M * G_sample)**2) / torch.mean(M)\n",
    "\n",
    "    G_loss = G_loss1 + alpha * MSE_train_loss \n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return G_loss, MSE_train_loss, MSE_test_loss\n",
    "    \n",
    "def test_loss(X, M, New_X):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return MSE_test_loss, G_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/5000 [00:00<28:40,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Train_loss: 0.3342\n",
      "Test_loss: 0.3383\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 114/5000 [00:01<01:23, 58.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Train_loss: 0.1941\n",
      "Test_loss: 0.204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 213/5000 [00:02<00:52, 91.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "Train_loss: 0.1566\n",
      "Test_loss: 0.1648\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 313/5000 [00:04<00:51, 91.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 300\n",
      "Train_loss: 0.1518\n",
      "Test_loss: 0.1504\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 413/5000 [00:05<00:49, 91.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 400\n",
      "Train_loss: 0.1436\n",
      "Test_loss: 0.1466\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 513/5000 [00:06<00:49, 91.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "Train_loss: 0.1314\n",
      "Test_loss: 0.1495\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 613/5000 [00:07<00:47, 92.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 600\n",
      "Train_loss: 0.1312\n",
      "Test_loss: 0.1401\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 713/5000 [00:08<00:46, 91.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 700\n",
      "Train_loss: 0.1193\n",
      "Test_loss: 0.1394\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 813/5000 [00:09<00:45, 92.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 800\n",
      "Train_loss: 0.1164\n",
      "Test_loss: 0.1321\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 913/5000 [00:10<00:44, 92.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 900\n",
      "Train_loss: 0.1097\n",
      "Test_loss: 0.1509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1013/5000 [00:11<00:43, 91.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1000\n",
      "Train_loss: 0.1071\n",
      "Test_loss: 0.1342\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1113/5000 [00:12<00:42, 91.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1100\n",
      "Train_loss: 0.1003\n",
      "Test_loss: 0.1343\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1213/5000 [00:13<00:41, 92.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1200\n",
      "Train_loss: 0.09141\n",
      "Test_loss: 0.1265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 1313/5000 [00:14<00:38, 95.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1300\n",
      "Train_loss: 0.09714\n",
      "Test_loss: 0.1375\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1413/5000 [00:16<00:39, 91.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1400\n",
      "Train_loss: 0.09017\n",
      "Test_loss: 0.1362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1513/5000 [00:17<00:38, 90.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1500\n",
      "Train_loss: 0.08389\n",
      "Test_loss: 0.1319\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1613/5000 [00:18<00:36, 92.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1600\n",
      "Train_loss: 0.08213\n",
      "Test_loss: 0.1454\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1713/5000 [00:19<00:36, 90.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1700\n",
      "Train_loss: 0.08541\n",
      "Test_loss: 0.1202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 1813/5000 [00:20<00:34, 92.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1800\n",
      "Train_loss: 0.08326\n",
      "Test_loss: 0.1381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1913/5000 [00:21<00:33, 92.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1900\n",
      "Train_loss: 0.07923\n",
      "Test_loss: 0.1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2013/5000 [00:22<00:32, 92.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2000\n",
      "Train_loss: 0.07596\n",
      "Test_loss: 0.1167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2113/5000 [00:23<00:31, 92.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2100\n",
      "Train_loss: 0.07772\n",
      "Test_loss: 0.1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2213/5000 [00:24<00:30, 91.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2200\n",
      "Train_loss: 0.07377\n",
      "Test_loss: 0.1291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 2313/5000 [00:25<00:28, 93.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2300\n",
      "Train_loss: 0.077\n",
      "Test_loss: 0.1381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2413/5000 [00:26<00:27, 93.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2400\n",
      "Train_loss: 0.07289\n",
      "Test_loss: 0.1358\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2513/5000 [00:27<00:27, 91.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2500\n",
      "Train_loss: 0.07455\n",
      "Test_loss: 0.1097\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2613/5000 [00:29<00:26, 91.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2600\n",
      "Train_loss: 0.07166\n",
      "Test_loss: 0.1192\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2713/5000 [00:30<00:24, 92.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2700\n",
      "Train_loss: 0.07104\n",
      "Test_loss: 0.1341\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 2813/5000 [00:31<00:23, 91.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2800\n",
      "Train_loss: 0.07514\n",
      "Test_loss: 0.1253\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2913/5000 [00:32<00:22, 91.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2900\n",
      "Train_loss: 0.07385\n",
      "Test_loss: 0.128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3013/5000 [00:33<00:21, 92.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3000\n",
      "Train_loss: 0.07921\n",
      "Test_loss: 0.1259\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 3113/5000 [00:34<00:20, 92.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3100\n",
      "Train_loss: 0.07544\n",
      "Test_loss: 0.1226\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3213/5000 [00:35<00:19, 91.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3200\n",
      "Train_loss: 0.07133\n",
      "Test_loss: 0.1232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 3313/5000 [00:36<00:18, 91.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3300\n",
      "Train_loss: 0.07411\n",
      "Test_loss: 0.1236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3413/5000 [00:37<00:17, 91.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3400\n",
      "Train_loss: 0.07162\n",
      "Test_loss: 0.1219\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3513/5000 [00:38<00:16, 91.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3500\n",
      "Train_loss: 0.07753\n",
      "Test_loss: 0.13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3613/5000 [00:39<00:14, 92.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3600\n",
      "Train_loss: 0.07649\n",
      "Test_loss: 0.1207\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3713/5000 [00:41<00:13, 92.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3700\n",
      "Train_loss: 0.07395\n",
      "Test_loss: 0.1342\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 3813/5000 [00:42<00:13, 90.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3800\n",
      "Train_loss: 0.07453\n",
      "Test_loss: 0.1296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3913/5000 [00:43<00:11, 91.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3900\n",
      "Train_loss: 0.07407\n",
      "Test_loss: 0.1282\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4013/5000 [00:44<00:10, 91.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4000\n",
      "Train_loss: 0.07186\n",
      "Test_loss: 0.1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4113/5000 [00:45<00:09, 91.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4100\n",
      "Train_loss: 0.06995\n",
      "Test_loss: 0.1297\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 4213/5000 [00:46<00:08, 88.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4200\n",
      "Train_loss: 0.06693\n",
      "Test_loss: 0.1224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 4310/5000 [00:47<00:08, 79.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4300\n",
      "Train_loss: 0.07387\n",
      "Test_loss: 0.1214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 4417/5000 [00:49<00:07, 79.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4400\n",
      "Train_loss: 0.07252\n",
      "Test_loss: 0.1273\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4516/5000 [00:50<00:05, 88.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4500\n",
      "Train_loss: 0.07322\n",
      "Test_loss: 0.1164\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 4616/5000 [00:51<00:04, 91.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4600\n",
      "Train_loss: 0.06921\n",
      "Test_loss: 0.1161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 4715/5000 [00:52<00:03, 86.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4700\n",
      "Train_loss: 0.07135\n",
      "Test_loss: 0.1336\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 4813/5000 [00:53<00:02, 78.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4800\n",
      "Train_loss: 0.06967\n",
      "Test_loss: 0.1255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 4911/5000 [00:54<00:01, 80.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4900\n",
      "Train_loss: 0.06921\n",
      "Test_loss: 0.1228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:55<00:00, 89.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#%% Optimizers\n",
    "optimizer_D = torch.optim.Adam(params=theta_D)\n",
    "optimizer_G = torch.optim.Adam(params=theta_G)\n",
    "\n",
    "#%% Iterations\n",
    "\n",
    "#%% Start Iterations\n",
    "for it in tqdm(range(5000)):    \n",
    "    \n",
    "    #%% Inputs\n",
    "    mb_idx = sample_idx(Train_No, mb_size)\n",
    "    X_mb = trainX[mb_idx,:]  \n",
    "    \n",
    "    Z_mb = sample_Z(mb_size, Dim) \n",
    "    M_mb = trainM[mb_idx,:]  \n",
    "    H_mb1 = sample_M(mb_size, Dim, 1-p_hint)\n",
    "    H_mb = M_mb * H_mb1\n",
    "    \n",
    "    New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "    \n",
    "    if use_gpu is True:\n",
    "        X_mb = torch.tensor(X_mb, device=\"cuda\")\n",
    "        M_mb = torch.tensor(M_mb, device=\"cuda\")\n",
    "        H_mb = torch.tensor(H_mb, device=\"cuda\")\n",
    "        New_X_mb = torch.tensor(New_X_mb, device=\"cuda\")\n",
    "    else:\n",
    "        X_mb = torch.tensor(X_mb)\n",
    "        M_mb = torch.tensor(M_mb)\n",
    "        H_mb = torch.tensor(H_mb)\n",
    "        New_X_mb = torch.tensor(New_X_mb)\n",
    "    \n",
    "    optimizer_D.zero_grad()\n",
    "    D_loss_curr = discriminator_loss(M=M_mb, New_X=New_X_mb, H=H_mb)\n",
    "    D_loss_curr.backward()\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    optimizer_G.zero_grad()\n",
    "    G_loss_curr, MSE_train_loss_curr, MSE_test_loss_curr = generator_loss(X=X_mb, M=M_mb, New_X=New_X_mb, H=H_mb)\n",
    "    G_loss_curr.backward()\n",
    "    optimizer_G.step()    \n",
    "        \n",
    "    #%% Intermediate Losses\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('Train_loss: {:.4}'.format(np.sqrt(MSE_train_loss_curr.item())))\n",
    "        print('Test_loss: {:.4}'.format(np.sqrt(MSE_test_loss_curr.item())))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test RMSE: 0.12446774813546198\n"
     ]
    }
   ],
   "source": [
    "#%% Final Loss\n",
    "    \n",
    "Z_mb = sample_Z(Test_No, Dim) \n",
    "M_mb = testM\n",
    "X_mb = testX\n",
    "        \n",
    "New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "\n",
    "if use_gpu is True:\n",
    "    X_mb = torch.tensor(X_mb, device='cuda')\n",
    "    M_mb = torch.tensor(M_mb, device='cuda')\n",
    "    New_X_mb = torch.tensor(New_X_mb, device='cuda')\n",
    "else:\n",
    "    X_mb = torch.tensor(X_mb)\n",
    "    M_mb = torch.tensor(M_mb)\n",
    "    New_X_mb = torch.tensor(New_X_mb)\n",
    "    \n",
    "MSE_final, Sample = test_loss(X=X_mb, M=M_mb, New_X=New_X_mb)\n",
    "        \n",
    "print('Final Test RMSE: ' + str(np.sqrt(MSE_final.item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed test data:\n",
      "[[0.13333332 0.26666665 0.26666665 ... 0.39999997 0.16881414 0.5333333 ]\n",
      " [0.26666665 0.39999997 0.26306941 ... 0.59999996 0.16587397 0.46666664]\n",
      " [0.19999999 0.13333332 0.33333331 ... 0.39999997 0.13333332 0.58901419]\n",
      " ...\n",
      " [0.13333332 0.36883384 0.26666665 ... 0.5333333  0.27967424 0.5333333 ]\n",
      " [0.19999999 0.39999997 0.39999997 ... 0.46666664 0.13333332 0.5333333 ]\n",
      " [0.33333331 0.56728029 0.41322088 ... 0.5333333  0.33333331 0.59999996]]\n"
     ]
    }
   ],
   "source": [
    "imputed_data = M_mb * X_mb + (1-M_mb) * Sample\n",
    "print(\"Imputed test data:\")\n",
    "# np.set_printoptions(formaM_mbtter={'float': lambda x: \"{0:0.8f}\".format(x)})\n",
    "\n",
    "if use_gpu is True:\n",
    "    print(imputed_data.cpu().detach().numpy())\n",
    "else:\n",
    "    print(imputed_data.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt]",
   "language": "python",
   "name": "conda-env-pt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
